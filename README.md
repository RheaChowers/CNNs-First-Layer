[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](.......ipynb)
# Why do CNNs Learn Consistent Representations in their First Layer Independent of Labels and Architecture?

A demo illustrating the results of ["Why do CNNs Learn Consistent Representations in their First Layer Independent of Labels and Architecture?"](https://arxiv.org/abs/2206.02454)


![Teaser](Readme_images/Teaser_Figure.png)

# Results on Pretrained Models
`
python3 scripts/reshuffle_datasets.py
`


# Citation
If you find this research interesting, feel free to cite:
```
@misc{https://doi.org/10.48550/arxiv.2206.02454,
  doi = {10.48550/ARXIV.2206.02454},
  url = {https://arxiv.org/abs/2206.02454},
  author = {Chowers, Rhea and Weiss, Yair},
  title = {Why do CNNs Learn Consistent Representations in their First Layer Independent of Labels and Architecture?},
  publisher = {arXiv},
  year = {2022},  
  copyright = {Creative Commons Attribution 4.0 International}
}

```
